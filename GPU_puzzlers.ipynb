{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af19204f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e38a0a34",
   "metadata": {},
   "source": [
    "# GPU Puzzles\n",
    "- by [Sasha Rush](http://rush-nlp.com) - [srush_nlp](https://twitter.com/srush_nlp) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64407d9d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/srush/GPU-Puzzles/blob/main/GPU%20Puzzlers.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60ce97",
   "metadata": {},
   "source": [
    "GPU architectures are critical to machine learning, and seem to be\n",
    "becoming even more important every day. Last year I thought it would be\n",
    "fun to give my students and assignment that asked them to write some basic\n",
    "algorithms for GPU in CUDA. It was a complete disaster. For some reason I\n",
    "had underestimated just how hard it is to grok this style of programming if\n",
    "you are used to NumPy or just standard serial Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48726f3",
   "metadata": {},
   "source": [
    "This notebook is an attempt to teach GPU programming in an\n",
    "interactive fashion by having the reader solve puzzles on their\n",
    "own. Instead of providing a textual guide that tries to explain the\n",
    "concepts, it throws you right in to coding and building little GPU\n",
    "boxes. If you are into this style, also check out my (Tensor\n",
    "Puzzles)[https://github.com/srush/Tensor-Puzzles] for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4db0d9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/danoneata/chalk@srush-patch-1\n",
    "!wget https://github.com/srush/GPU-Puzzles/raw/main/robot.png https://github.com/srush/GPU-Puzzles/raw/main/lib.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80657371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "import warnings\n",
    "from lib import CudaProblem, Coord\n",
    "warnings.filterwarnings(action='ignore', category=numba.NumbaPerformanceWarning, module='numba')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25de5c1",
   "metadata": {},
   "source": [
    "## Puzzle 1: Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0c9954",
   "metadata": {},
   "source": [
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`.\n",
    "You have 1 thread per position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472df5e2",
   "metadata": {},
   "source": [
    "*Tip: Think of the function `call` as being run 1 time for each thread.\n",
    "The only difference is that `cuda.threadIdx.x` changes each time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65ebbe",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def map_spec(a):\n",
    "    return a + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7adb094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_test(cuda):\n",
    "    def call(out, a) -> None:\n",
    "        local_i = cuda.threadIdx.x\n",
    "        # FILL ME IN (roughly 1 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66acc086",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 4\n",
    "out = np.zeros((SIZE,))\n",
    "a = np.arange(SIZE)\n",
    "problem = CudaProblem(\"Map\", map_test, [a], out,\n",
    "                      threadsperblock=Coord(SIZE, 1),\n",
    "                      spec=map_spec)\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd8efd0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e60cc3",
   "metadata": {},
   "source": [
    "## Puzzle 2 - Zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f2ade0",
   "metadata": {},
   "source": [
    "Implement a kernel that adds together each position of `a` and `b` and stores it in `out`.\n",
    "You have 1 thread per position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc203b7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def zip_spec(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a691700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_test(cuda):\n",
    "    def call(out, a, b) -> None:\n",
    "        local_i = cuda.threadIdx.x\n",
    "        # FILL ME IN (roughly 1 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 4\n",
    "out = np.zeros((SIZE,))\n",
    "a = np.arange(SIZE)\n",
    "b = np.arange(SIZE)\n",
    "problem = CudaProblem(\"Zip\", zip_test, [a, b], out,\n",
    "                      threadsperblock=Coord(SIZE, 1),\n",
    "                      spec=zip_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66208505",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca750f0",
   "metadata": {},
   "source": [
    "## Puzzle 3 - Guards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f8543",
   "metadata": {},
   "source": [
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`.\n",
    "You have more threads than positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53aa1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_guard_test(cuda):\n",
    "    def call(out, a, size) -> None:\n",
    "        local_i = cuda.threadIdx.x\n",
    "        # FILL ME IN (roughly 2 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabe556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 4\n",
    "out = np.zeros((SIZE,))\n",
    "a = np.arange(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Guard\", map_guard_test, [a], out, [SIZE],\n",
    "    threadsperblock=Coord(8, 1),\n",
    "    spec=map_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af373c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a9131",
   "metadata": {},
   "source": [
    "## Puzzle 4 - Map 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb71fc5",
   "metadata": {},
   "source": [
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`.\n",
    "Input `a` is 2D and square. You have more threads than positions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae75d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_2D_test(cuda):\n",
    "    def call(out, a, size) -> None:\n",
    "        local_i = cuda.threadIdx.x\n",
    "        local_j = cuda.threadIdx.y\n",
    "        # FILL ME IN (roughly 2 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59bb3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 2\n",
    "out = np.zeros((SIZE, SIZE))\n",
    "a = np.arange(SIZE*SIZE).reshape((SIZE, SIZE))\n",
    "problem = CudaProblem(\n",
    "    \"Map 2D\", map_2D_test, [a], out, [SIZE], threadsperblock=Coord(3, 3),\n",
    "    spec=map_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f881e",
   "metadata": {},
   "source": [
    "## Puzzle 5 - Broadcast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead670ac",
   "metadata": {},
   "source": [
    "Implement a kernel that adds `a` and `b` and stores it in `out`.\n",
    "Inputs `a` and `b` are vectors. You have more threads than positions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460257cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_test(cuda):\n",
    "    def call(out, a, b, size) -> None:\n",
    "        local_i = cuda.threadIdx.x\n",
    "        local_j = cuda.threadIdx.y\n",
    "        # FILL ME IN (roughly 2 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad1aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 2\n",
    "out = np.zeros((SIZE, SIZE))\n",
    "a = np.arange(SIZE).reshape(SIZE, 1)\n",
    "b = np.arange(SIZE).reshape(1, SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Broadcast\", broadcast_test, [a, b], out, [SIZE], threadsperblock=Coord(3, 3),\n",
    "    spec=zip_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72052c1",
   "metadata": {},
   "source": [
    "## Puzzle 6 - Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a97abd",
   "metadata": {},
   "source": [
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`.\n",
    "You have less threads per block than the size of `a`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c508d005",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "*Tip: A block is a group of threads. The number of threads per block is limited, but we can\n",
    "have many different blocks. Variable `cuda.blockIdx` tells us what block we are in.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d5663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_block_test(cuda):\n",
    "    def call(out, a, size) -> None:\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        # FILL ME IN (roughly 2 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d45ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 9\n",
    "out = np.zeros((SIZE,))\n",
    "a = np.arange(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Blocks\",\n",
    "    map_block_test,\n",
    "    [a],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    threadsperblock=Coord(4, 1),\n",
    "    blockspergrid=Coord(3, 1),\n",
    "    spec=map_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84454920",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab36c8a",
   "metadata": {},
   "source": [
    "Puzzle 7 - Blocks 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428ab38",
   "metadata": {},
   "source": [
    "Implement the same kernel in 2D.  You have less threads per block\n",
    "than the size of `a` in both directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed261cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_block2D_test(cuda):\n",
    "    def call(out, a, size) -> None:\n",
    "        # FILL ME IN (roughly 5 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e9b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 5\n",
    "out = np.zeros((SIZE, SIZE))\n",
    "a = np.ones((SIZE, SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f85a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = CudaProblem(\n",
    "    \"Blocks 2D\",\n",
    "    map_block2D_test,\n",
    "    [a],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    threadsperblock=Coord(3, 3),\n",
    "    blockspergrid=Coord(2, 2),\n",
    "    spec=map_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84665a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c6ae1",
   "metadata": {},
   "source": [
    "Puzzle 8 - Shared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a47fe",
   "metadata": {},
   "source": [
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`.\n",
    "You have less threads per block than the size of `a`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0369c5e",
   "metadata": {},
   "source": [
    "*Tip: Each block can have a constant amount of shared memory that\n",
    "only threads in that block can read and write to.\n",
    "After writing you should use `cuda.syncthreads` to ensure that threads do not cross.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d3687",
   "metadata": {},
   "source": [
    "(This example does not really need shared memory or syncthreads, but it is a demo.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d3ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPB = 4\n",
    "def shared_test(cuda):\n",
    "    def call(out, a, size) -> None:\n",
    "        shared = cuda.shared.array(TPB, numba.float32)\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        local_i = cuda.threadIdx.x\n",
    "\n",
    "        if i < size:\n",
    "            shared[local_i] = a[i]\n",
    "            cuda.syncthreads()\n",
    "\n",
    "        # FILL ME IN (roughly 2 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c748539",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 8\n",
    "out = np.zeros(SIZE)\n",
    "a = np.ones(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Shared\",\n",
    "    shared_test,\n",
    "    [a],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    threadsperblock=Coord(TPB, 1),\n",
    "    blockspergrid=Coord(2, 1),\n",
    "    spec=map_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e095c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2d7c4a",
   "metadata": {},
   "source": [
    "## Puzzle 9 - Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ccc98",
   "metadata": {},
   "source": [
    "Implement a kernel that sums together the last 3 position of `a` and stores it in `out`.\n",
    "You have 1 thread per position. You only need 1 global read and 1 global write per thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92028cc2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def pool_spec(a):\n",
    "    out = np.zeros(*a.shape)\n",
    "    for i in range(a.shape[0]):\n",
    "        out[i] = a[max(i-2,0):i+1].sum()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPB = 8\n",
    "def pool_test(cuda):\n",
    "    def call(out, a, size) -> None:\n",
    "        shared = cuda.shared.array(TPB, numba.float32)\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        local_i = cuda.threadIdx.x\n",
    "        # FILL ME IN (roughly 8 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e479ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 8\n",
    "out = np.zeros(SIZE)\n",
    "a = np.arange(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Pooling\",\n",
    "    pool_test,\n",
    "    [a],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    threadsperblock=Coord(TPB, 1),\n",
    "    blockspergrid=Coord(1, 1),\n",
    "    spec=pool_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828bc2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95603a94",
   "metadata": {},
   "source": [
    "## Puzzle 10 - Dot Product\n",
    "\n",
    "Implement a kernel that computes the dot-product of `a` and `b` and stores it in `out`.\n",
    "You have 1 thread per position. You only need 1 global read and 1 global write per thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57730fbf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def dot_spec(a, b):\n",
    "    return a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4483f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPB = 8\n",
    "def dot_test(cuda):\n",
    "    def call(out, a, b, size) -> None:\n",
    "        a_shared = cuda.shared.array(TPB, numba.float32)\n",
    "        b_shared = cuda.shared.array(TPB, numba.float32)\n",
    "\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        local_i = cuda.threadIdx.x\n",
    "        # FILL ME IN (roughly 9 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 8\n",
    "out = np.zeros(1)\n",
    "a = np.arange(SIZE)\n",
    "b = np.arange(SIZE)\n",
    "problem = CudaProblem(\n",
    "    \"Dot\",\n",
    "    dot_test,\n",
    "    [a, b],\n",
    "    out,\n",
    "    [SIZE],\n",
    "    threadsperblock=Coord(SIZE, 1),\n",
    "    blockspergrid=Coord(1, 1),\n",
    "    spec=dot_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ee83c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a89b7",
   "metadata": {},
   "source": [
    "## Puzzle 11 - 1D Convolution\n",
    "\n",
    "Implement a kernel that computes a 1D convolution between `a` and `b` and stores it in `out`.\n",
    "You need to handle the general case. You only need 2 global reads and 1 global write per thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba520434",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def conv_spec(a, b):\n",
    "    out = np.zeros(*a.shape)\n",
    "    len = b.shape[0]\n",
    "    for i in range(a.shape[0]):\n",
    "        out[i] = sum([a[i + j] * b[j] for j in range(len) if i + j < a.shape[0]])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e50700",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CONV = 5\n",
    "TPB = 8\n",
    "TPB_MAX_CONV = TPB+MAX_CONV\n",
    "def conv_test(cuda):\n",
    "    def call(out, a, b, a_size, b_size) -> None:\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        local_i = cuda.threadIdx.x\n",
    "\n",
    "\n",
    "        # FILL ME IN (roughly 17 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3184b0b2",
   "metadata": {},
   "source": [
    "Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1741f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 6\n",
    "CONV = 3\n",
    "out = np.zeros(SIZE)\n",
    "a = np.arange(SIZE)\n",
    "b = np.arange(CONV)\n",
    "problem = CudaProblem(\n",
    "    \"1D Conv (Simple)\", conv_test, [a, b], out, [SIZE, CONV], Coord(1, 1), Coord(TPB, 1), spec=conv_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933319b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e564ff",
   "metadata": {},
   "source": [
    "Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros(15)\n",
    "a = np.arange(15)\n",
    "b = np.arange(4)\n",
    "problem = CudaProblem(\"1D Conv (Full)\", conv_test, [a, b], out, [15, 4], Coord(2, 1), Coord(TPB, 1), spec=conv_spec)\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a88059",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b619df1",
   "metadata": {},
   "source": [
    "## Puzzle 12 - Prefix Sum \n",
    "\n",
    "Implement a kernel that computes a sum over `a` and stores it in `out`.\n",
    "If the size of `a` is greater than the block size, only store the sum of\n",
    "each block. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b46d5",
   "metadata": {},
   "source": [
    "We will do this, using the *parallel prefix sum* algorithm in shared memory.\n",
    "That is each step of the algorithm should sum together half the remaining numbers.\n",
    "Follow the top half of this diagram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553cdd09",
   "metadata": {},
   "source": [
    "!()[https://en.wikipedia.org/wiki/Prefix_sum#/media/File:Prefix_sum_16.svg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efb1cbc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "TPB = 8\n",
    "def sum_spec(a):\n",
    "    out = np.zeros((a.shape[0] + TPB - 1) // TPB)\n",
    "    for j, i in enumerate(range(0, a.shape[-1], TPB)):\n",
    "        out[j] = a[i: i +TPB].sum()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6de22",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def sum_test(cuda):\n",
    "    def call(out, a, size: int) -> None:\n",
    "        cache = cuda.shared.array(TPB, numba.float32)\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        local_i = cuda.threadIdx.x\n",
    "        # FILL ME IN (roughly 12 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d421a",
   "metadata": {},
   "source": [
    "Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 8\n",
    "out = np.zeros(1)\n",
    "inp = np.arange(SIZE)\n",
    "problem = CudaProblem(\"Sum (Simple)\", sum_test, [inp], out, [SIZE], Coord(1, 1), Coord(TPB, 1), spec=sum_spec)\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f1de96",
   "metadata": {},
   "source": [
    "Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78724617",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 15\n",
    "out = np.zeros(2)\n",
    "inp = np.arange(SIZE)\n",
    "problem = CudaProblem(\"Sum (Full)\", sum_test, [inp], out, [SIZE], Coord(2, 1), Coord(TPB, 1), spec=sum_spec)\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0960beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500f083",
   "metadata": {},
   "source": [
    "## Puzzle 13 - Axis Sum\n",
    "\n",
    "Implement a kernel that computes a sum over each row of `a` and stores it in `out`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a78f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPB = 8\n",
    "def sum_spec(a):\n",
    "    out = np.zeros((a.shape[0], (a.shape[1] + TPB - 1) // TPB))\n",
    "    for j, i in enumerate(range(0, a.shape[-1], TPB)):\n",
    "        out[..., j] = a[..., i: i +TPB].sum(-1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a6a29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_sum_test(cuda):\n",
    "    def call(out, a, size: int) -> None:\n",
    "        cache = cuda.shared.array(TPB, numba.float32)\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        local_i = cuda.threadIdx.x\n",
    "        batch = cuda.blockIdx.y\n",
    "        # FILL ME IN (roughly 12 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7fa1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 4\n",
    "SIZE = 6\n",
    "out = np.zeros((BATCH, 1))\n",
    "inp = np.arange(BATCH*SIZE).reshape((BATCH, SIZE))\n",
    "problem = CudaProblem(\n",
    "    \"Axis Sum\", axis_sum_test, [inp], out, [SIZE], Coord(1, BATCH), Coord(TPB, 1), spec=sum_spec\n",
    ")\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76028dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e25bf",
   "metadata": {},
   "source": [
    "## Puzzle 14 - Matrix Multiply! \n",
    "\n",
    "Implement a kernel that multiplies square matrices `a` and `b` and\n",
    "stores it in `out`.\n",
    "\n",
    "*Tip: The most efficient algorithm here will copy a block into\n",
    " shared memory before computing each of the individual row-column\n",
    " dot products. This is easy to do if the matrix fits in shared\n",
    " memory.  Do that case first. Then update your code so that compute\n",
    " a partial dot-product and then iteratively move the part that you\n",
    " copied into shared memory.* You should be able to do the hard case\n",
    " in 6 global reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d54e9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def matmul_spec(a, b):\n",
    "    return a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3edba77",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "TPB = 3\n",
    "def mm_oneblock_test(cuda):\n",
    "    def call(out, a, b, size: int) -> None:\n",
    "        a_shared = cuda.shared.array((TPB, TPB), numba.float32)\n",
    "        b_shared = cuda.shared.array((TPB, TPB), numba.float32)\n",
    "\n",
    "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "        j = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
    "        local_i = cuda.threadIdx.x\n",
    "        local_j = cuda.threadIdx.y\n",
    "        # FILL ME IN (roughly 14 lines)\n",
    "\n",
    "    return call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3095d57f",
   "metadata": {},
   "source": [
    "Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e935d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 2\n",
    "out = np.zeros((SIZE, SIZE))\n",
    "inp1 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE))\n",
    "inp2 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d956227",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = CudaProblem(\n",
    "    \"Matmul (Simple)\", mm_oneblock_test, [inp1, inp2], out, [SIZE], Coord(1, 1), Coord(TPB, TPB), spec=matmul_spec\n",
    ")\n",
    "problem.show(sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa7cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2\n",
    "SIZE = 8\n",
    "out = np.zeros((SIZE, SIZE))\n",
    "inp1 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE))\n",
    "inp2 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8fa9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = CudaProblem(\n",
    "    \"Matmul (Full)\", mm_oneblock_test, [inp1, inp2], out, [SIZE], Coord(3, 3), Coord(TPB, TPB), spec=matmul_spec\n",
    ")\n",
    "problem.show(sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2390e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.check()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
